{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJuPzt3SYNdRbHxvOAPWI1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshata1992/Implement_ResearchPaper/blob/main/AlexNet_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1JE0dViAKk8"
      },
      "source": [
        "Implementing AlexNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIz1nyBL9x2b"
      },
      "source": [
        "#Import all necessary libraries\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense,Activation,Conv2D,Flatten,Dropout,MaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.losses import CategoricalCrossentropy\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUz42mTM_eef"
      },
      "source": [
        "#Initialize random seed\r\n",
        "np.random.seed(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPu2-FWm_tUc"
      },
      "source": [
        "The network consists of a kernel or filters with size 11 x 11, 5 x 5, 3 x 3, 3 x 3 and 3 x 3 for its five convolutional layers respectively,3 fully connected layers, ReLU as an activation function at all layers except at the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlIxpG2p_pd-",
        "outputId": "db7e929a-c9cf-4cc2-d82f-95f821db65b3"
      },
      "source": [
        "#Instantiate the model\r\n",
        "AlexNet = Sequential()\r\n",
        "\r\n",
        "#Conv Layer -1 \r\n",
        "AlexNet.add(Conv2D(filters=96,kernel_size=(3,3),strides=(4,4),input_shape=(32,32,3), activation='relu'))\r\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\r\n",
        "\r\n",
        "#Conv Layer - 2\r\n",
        "AlexNet.add(Conv2D(256,kernel_size=(5,5),strides=(1,1),padding='same',activation='relu'))\r\n",
        "AlexNet.add(BatchNormalization())\r\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\r\n",
        "\r\n",
        "#Conv Layer - 3\r\n",
        "AlexNet.add(Conv2D(384,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\r\n",
        "\r\n",
        "#Conv Layer - 4\r\n",
        "AlexNet.add(Conv2D(384,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\r\n",
        "\r\n",
        "#Conv Layer - 5\r\n",
        "AlexNet.add(Conv2D(256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\r\n",
        "AlexNet.add(BatchNormalization())\r\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\r\n",
        "\r\n",
        "#Flatten the layers\r\n",
        "AlexNet.add(Flatten())\r\n",
        "\r\n",
        "#Fully Connected layer - 1\r\n",
        "AlexNet.add(Dense(4096))\r\n",
        "AlexNet.add(Activation('relu'))\r\n",
        "#Add drop out to prevent overfitting\r\n",
        "AlexNet.add(Dropout(0.4))\r\n",
        "\r\n",
        "#Fully Connected layer - 2\r\n",
        "AlexNet.add(Dense(4096))\r\n",
        "AlexNet.add(Activation('relu'))\r\n",
        "#Add drop out to prevent overfitting\r\n",
        "AlexNet.add(Dropout(0.4))\r\n",
        "\r\n",
        "#Output layer\r\n",
        "AlexNet.add(Dense(10))\r\n",
        "AlexNet.add(Activation('softmax'))\r\n",
        "\r\n",
        "AlexNet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 96)          2688      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                40970     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 21,591,946\n",
            "Trainable params: 21,590,922\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq2Jpb1X_pnm"
      },
      "source": [
        "#Compile the model\r\n",
        "AlexNet.compile(optimizer='SGD',loss='CategoricalCrossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5rldn4R_psz"
      },
      "source": [
        "#Keras library for CIFAR10 dataset\r\n",
        "from keras.datasets import cifar10\r\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3nkiim02ZT_"
      },
      "source": [
        "# train test split using sklearn \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjHyW9XT2Zfx",
        "outputId": "19f37257-88be-4fad-c387-ddb184debe1a"
      },
      "source": [
        "#dimention of cifar dataset\r\n",
        "print(x_train.shape)\r\n",
        "print(x_val.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 32, 32, 3)\n",
            "(15000, 32, 32, 3)\n",
            "(35000, 1)\n",
            "(15000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veS8Vg162ZrN",
        "outputId": "f709dfc4-391e-448a-b80a-5a1b3e68be06"
      },
      "source": [
        "#One hot encoding the labels\r\n",
        "from sklearn.utils.multiclass import unique_labels\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "y_train = to_categorical(y_train)\r\n",
        "y_val = to_categorical(y_val)\r\n",
        "y_test = to_categorical(y_test)\r\n",
        "\r\n",
        "print(y_train.shape)\r\n",
        "print(y_val.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 10)\n",
            "(15000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pls1uSAh317V"
      },
      "source": [
        "#Image Data Augmentation\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "train_generator = ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=0.1)\r\n",
        "val_generator = ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=0.1)\r\n",
        "test_generator = ImageDataGenerator(rotation_range=2,horizontal_flip=True,zoom_range=0.1)\r\n",
        "\r\n",
        "#Fit the dataset to transformation\r\n",
        "train_generator.fit(x_train)\r\n",
        "val_generator.fit(x_val)\r\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zlyOZqe5OcV"
      },
      "source": [
        "#Learning rate Annealer\r\n",
        "from keras.callbacks import ReduceLROnPlateau\r\n",
        "lrr = ReduceLROnPlateau(monitor='val_acc',factor=0.01,patience=3,min_lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q1cCeSs5OoM"
      },
      "source": [
        "#Defining parameters for model fitting\r\n",
        "batch_size = 100\r\n",
        "epochs = 200\r\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abTvL5pZ5Ovz",
        "outputId": "43c3b0ff-52d4-41da-b859-81ad7c7daf9d"
      },
      "source": [
        "#Fit the model\r\n",
        "AlexNet.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\r\n",
        "                      validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,callbacks=[lrr],verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 1.8495 - accuracy: 0.3189WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "350/350 [==============================] - 23s 65ms/step - loss: 1.8495 - accuracy: 0.3189 - val_loss: 1.8938 - val_accuracy: 0.3645\n",
            "Epoch 2/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 1.5323 - accuracy: 0.4400WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.5323 - accuracy: 0.4400\n",
            "Epoch 3/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.4019 - accuracy: 0.4952WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 50ms/step - loss: 1.4019 - accuracy: 0.4952\n",
            "Epoch 4/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 1.3251 - accuracy: 0.5242WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.3251 - accuracy: 0.5242\n",
            "Epoch 5/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.2649 - accuracy: 0.5477WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.2646 - accuracy: 0.5478\n",
            "Epoch 6/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.2075 - accuracy: 0.5655WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.2072 - accuracy: 0.5656\n",
            "Epoch 7/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.1656 - accuracy: 0.5854WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.1658 - accuracy: 0.5854\n",
            "Epoch 8/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.1275 - accuracy: 0.6011WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.1276 - accuracy: 0.6010\n",
            "Epoch 9/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.0969 - accuracy: 0.6083WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.0973 - accuracy: 0.6082\n",
            "Epoch 10/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 1.0584 - accuracy: 0.6274WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 1.0584 - accuracy: 0.6274\n",
            "Epoch 11/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.0322 - accuracy: 0.6332WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.0319 - accuracy: 0.6333\n",
            "Epoch 12/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 1.0052 - accuracy: 0.6428WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.0051 - accuracy: 0.6428\n",
            "Epoch 13/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 0.9797 - accuracy: 0.6539WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.9797 - accuracy: 0.6539\n",
            "Epoch 14/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 0.9500 - accuracy: 0.6640WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.9500 - accuracy: 0.6640\n",
            "Epoch 15/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 0.9262 - accuracy: 0.6705WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 18s 52ms/step - loss: 0.9262 - accuracy: 0.6705\n",
            "Epoch 16/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 0.9088 - accuracy: 0.6779WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 18s 52ms/step - loss: 0.9088 - accuracy: 0.6779\n",
            "Epoch 17/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.6910WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.8753 - accuracy: 0.6910\n",
            "Epoch 18/200\n",
            "349/350 [============================>.] - ETA: 0s - loss: 0.8648 - accuracy: 0.6938WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "350/350 [==============================] - 18s 52ms/step - loss: 0.8643 - accuracy: 0.6939\n",
            "Epoch 19/200\n",
            "  4/350 [..............................] - ETA: 12s - loss: 0.8277 - accuracy: 0.6925"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGTHfOyN89V1"
      },
      "source": [
        "#Visualize the performance\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#plotting loss and accuracy\r\n",
        "f,ax = plt.subplots(2,1)\r\n",
        "\r\n",
        "#loss graph\r\n",
        "ax[0].plot(AlexNet.history.history['loss'],color='b',label='Training Loss')\r\n",
        "ax[0].plot(AlexNet.history.history['val_loss'],color='r',label='Validation Loss')\r\n",
        "\r\n",
        "#Accuracy graph\r\n",
        "ax[1].plot(AlexNet.history.history['accuracy'],color='b',label='Training Accuracy')\r\n",
        "ax[1].plot(AlexNet.history.history['val_accuracy'],color='r',label='Validation Accuracy')\r\n",
        "\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaJ0ICeF_QKd"
      },
      "source": [
        "# Plotting the Confusion Matrics\r\n",
        "def plot_confusion_matrix(y_true,y_pred,\r\n",
        "                           classes,normalize=False,\r\n",
        "                           title=None,\r\n",
        "                           cmap=plt.cm.Blues):\r\n",
        "  \r\n",
        "  if not title:\r\n",
        "    if normalize:\r\n",
        "      title = 'Normalized Confusion Matrics'\r\n",
        "    else:\r\n",
        "      title = 'Non-Normalized Confusion Matrics'\r\n",
        "\r\n",
        "  cm = confusion_matrix(y_true,y_pred)\r\n",
        "  if normalize:\r\n",
        "    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\r\n",
        "    print('Normalized Confusion Matrix')\r\n",
        "  else:\r\n",
        "    print('Non-Normalized Confusion matrix')\r\n",
        "\r\n",
        "  #print the confusion matrix\r\n",
        "  fig,ax = plt.subplots(figsize=(7,7))\r\n",
        "  im = ax.imshow(cm,interpolation='nearest',cmap=cmap)\r\n",
        "  ax.figure.colorbar(im,ax=ax)\r\n",
        "\r\n",
        "  ax.set(xticks=np.arange(cm.shape[1]),\r\n",
        "           yticks=np.arange(cm.shape[0]),\r\n",
        "           xticklabels=classes, yticklabels=classes,\r\n",
        "           title=title,\r\n",
        "           ylabel='True label',\r\n",
        "           xlabel='Predicted label')\r\n",
        "\r\n",
        "  # Rotate the tick labels and set their alignment.\r\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\r\n",
        "             rotation_mode=\"anchor\")\r\n",
        "    # Loop over data dimensions and create text annotations.\r\n",
        "  fmt = '.2f' if normalize else 'd'\r\n",
        "  thresh = cm.max() / 2.\r\n",
        "  for i in range(cm.shape[0]):\r\n",
        "    for j in range(cm.shape[1]):\r\n",
        "          ax.text(j, i, format(cm[i, j], fmt),\r\n",
        "                  ha=\"center\", va=\"center\",\r\n",
        "                  color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "  fig.tight_layout()\r\n",
        "  return ax\r\n",
        "\r\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL_b6GGgBSib"
      },
      "source": [
        "#Making predictions for test images\r\n",
        "y_pred = AlexNet.predict_classes(x_test)\r\n",
        "y_true = np.argmax(y_test,axis=1)\r\n",
        "\r\n",
        "#Plot the confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "confusion_mtx=confusion_matrix(y_true,y_pred)\r\n",
        "\r\n",
        "class_names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\r\n",
        "\r\n",
        "# Plotting non-normalized confusion matrix\r\n",
        "plot_confusion_matrix(y_true, y_pred, classes = class_names,title = 'Confusion matrix, without normalization')\r\n",
        "\r\n",
        "# Plotting normalized confusion matrix\r\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names, normalize=True, title='Normalized confusion matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3xwTVHOB_t_"
      },
      "source": [
        "#Classification Accuracy\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "print(\"Accuracy Score : \",accuracy_score(y_true,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}